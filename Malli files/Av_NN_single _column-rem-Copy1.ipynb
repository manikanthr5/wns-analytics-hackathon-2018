{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#library imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function and model imports\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import scale\n",
    "\n",
    "#from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import svm\n",
    "\n",
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dell\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_shuffle(inp):\n",
    "    inp=shuffle(inp)\n",
    "    inp=inp.reset_index(drop=True)\n",
    "    return inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(54808, 14)\n",
      "(23490, 13)\n"
     ]
    }
   ],
   "source": [
    "train_data=pd.read_csv('../Data/train_LZdllcl.csv')\n",
    "test_data=pd.read_csv('../Data/test_2umaH9m.csv')\n",
    "print(train_data.shape)\n",
    "print(test_data.shape)\n",
    "#tr_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=df_shuffle(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "education               2409\n",
       "previous_year_rating    4124\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t=train_data.isnull().sum()\n",
    "t[t>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_categorical(train,test):    #use this after removing target variable\n",
    "    fulldata=pd.concat([train,test],axis=0)\n",
    "    fulldata=fulldata.fillna(-1)\n",
    "    #fulldata=fulldata.drop('region',axis=1)\n",
    "    fulldata['region']=fulldata['region'].apply(lambda x : int(x[7:]))\n",
    "    trainend=len(train)\n",
    "    onecoded=pd.get_dummies(fulldata)\n",
    "    return (onecoded[:trainend],onecoded[trainend:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop target variable for preprocessing\n",
    "X_train=train_data.drop('is_promoted',axis=1)\n",
    "y_data = train_data\n",
    "#y_data = train_data.loc[train_data['department']==\"R&D\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "xtrainfull,xtestproc=process_categorical(X_train,test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ytrainfull=y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#sample train data to test on itself\n",
    "end = 40000 \n",
    "xtrain = xtrainfull[:end]\n",
    "ytrain = ytrainfull[:end]\n",
    "\n",
    "xvalid = xtrainfull[end:54801] \n",
    "yvalid = ytrainfull[end:54801]\n",
    "xvalid=xvalid.reset_index(drop=True)\n",
    "yvalid=yvalid.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40000, 27)"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>employee_id</th>\n",
       "      <th>region</th>\n",
       "      <th>no_of_trainings</th>\n",
       "      <th>age</th>\n",
       "      <th>previous_year_rating</th>\n",
       "      <th>length_of_service</th>\n",
       "      <th>KPIs_met &gt;80%</th>\n",
       "      <th>awards_won?</th>\n",
       "      <th>avg_training_score</th>\n",
       "      <th>department_Analytics</th>\n",
       "      <th>...</th>\n",
       "      <th>department_Technology</th>\n",
       "      <th>education_-1</th>\n",
       "      <th>education_Bachelor's</th>\n",
       "      <th>education_Below Secondary</th>\n",
       "      <th>education_Master's &amp; above</th>\n",
       "      <th>gender_f</th>\n",
       "      <th>gender_m</th>\n",
       "      <th>recruitment_channel_other</th>\n",
       "      <th>recruitment_channel_referred</th>\n",
       "      <th>recruitment_channel_sourcing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16171</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>76636</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14565</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44835</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40563</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   employee_id  region  no_of_trainings  age  previous_year_rating  \\\n",
       "0        16171      27                1   35                   4.0   \n",
       "1        76636       2                1   31                  -1.0   \n",
       "2        14565       2                1   38                   5.0   \n",
       "3        44835       6                1   26                   3.0   \n",
       "4        40563      22                1   25                  -1.0   \n",
       "\n",
       "   length_of_service  KPIs_met >80%  awards_won?  avg_training_score  \\\n",
       "0                  8              0            0                  58   \n",
       "1                  1              0            0                  56   \n",
       "2                  5              0            0                  58   \n",
       "3                  3              0            0                  78   \n",
       "4                  1              1            0                  48   \n",
       "\n",
       "   department_Analytics              ...               department_Technology  \\\n",
       "0                     0              ...                                   0   \n",
       "1                     0              ...                                   0   \n",
       "2                     0              ...                                   0   \n",
       "3                     0              ...                                   1   \n",
       "4                     0              ...                                   0   \n",
       "\n",
       "   education_-1  education_Bachelor's  education_Below Secondary  \\\n",
       "0             0                     1                          0   \n",
       "1             0                     1                          0   \n",
       "2             0                     1                          0   \n",
       "3             0                     1                          0   \n",
       "4             0                     1                          0   \n",
       "\n",
       "   education_Master's & above  gender_f  gender_m  recruitment_channel_other  \\\n",
       "0                           0         0         1                          0   \n",
       "1                           0         1         0                          1   \n",
       "2                           0         1         0                          1   \n",
       "3                           0         1         0                          0   \n",
       "4                           0         0         1                          0   \n",
       "\n",
       "   recruitment_channel_referred  recruitment_channel_sourcing  \n",
       "0                             0                             1  \n",
       "1                             0                             0  \n",
       "2                             0                             0  \n",
       "3                             0                             1  \n",
       "4                             0                             1  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "ytrain.shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "X_train_std=xtrain\n",
    "X_test_std=xvalid\n",
    "X_sub_std=xtestproc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_std=scale(xtrain)\n",
    "X_test_std=scale(xvalid)\n",
    "X_sub_std=scale(xtestproc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_std = xtrain.loc[xtrain['department_Sales & Marketing']==1]\n",
    "X_test_std = xvalid.loc[xvalid['department_Sales & Marketing']==1]\n",
    "to_remove =['department_Finance','department_Legal','department_Sales & Marketing','department_Analytics','department_Technology','department_Procurement','department_Operations','department_HR','department_R&D']\n",
    "X_train_std = X_train_std[X_train_std.columns.difference(to_remove)]\n",
    "X_test_std = X_test_std[X_test_std.columns.difference(to_remove)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytrain = ytrain.loc[ytrain['department']==\"Sales & Marketing\"]\n",
    "ytrain = ytrain['is_promoted']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12271,)"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "yvalid = yvalid.loc[yvalid['department']==\"Sales & Marketing\"]\n",
    "yvalid = yvalid['is_promoted']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12271, 18)"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_std.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_bin_train = pd.get_dummies(ytrain)\n",
    "Y_bin_test = pd.get_dummies(yvalid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12271, 2)"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_bin_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "learning_rate =0.005 #0.02\n",
    "#num_steps = 500\n",
    "batch_size = 520#128\n",
    "#display_step = 100\n",
    "\n",
    "# Network Parameters\n",
    "n_hidden_1 = 30#36 # 1st layer number of neurons\n",
    "n_hidden_2 = 20#24 # 2nd layer number of neurons\n",
    "n_hidden_3 = 10#12\n",
    "num_input = 18 # MNIST data input (img shape: 28*28)\n",
    "num_classes = 2 # MNIST total classes (0-9 digits)\n",
    "\n",
    "\n",
    "# tf Graph input\n",
    "X = tf.placeholder(\"float\", [None, num_input])\n",
    "Y = tf.placeholder(\"float\", [None, num_classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store layers weight & bias\n",
    "inz = tf.contrib.layers.xavier_initializer()\n",
    "weights = {\n",
    "    'h1': tf.Variable(tf.random_normal([num_input, n_hidden_1])),\n",
    "    'h2': tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2])),\n",
    "    'h3': tf.Variable(tf.random_normal([n_hidden_2, n_hidden_3])),\n",
    "    'out': tf.Variable(tf.random_normal([n_hidden_3, num_classes]))\n",
    "}\n",
    "biases = {\n",
    "    'b1': tf.Variable(tf.random_normal([n_hidden_1])),\n",
    "    'b2': tf.Variable(tf.random_normal([n_hidden_2])),\n",
    "    'b3': tf.Variable(tf.random_normal([n_hidden_3])),\n",
    "    'out': tf.Variable(tf.random_normal([num_classes]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model\n",
    "def neural_net(x):\n",
    "    # Hidden fully connected layer with 256 neurons\n",
    "    layer_1 = tf.add(tf.matmul(x, weights['h1']), biases['b1'])\n",
    "    layer_1 = tf.nn.sigmoid(layer_1)\n",
    "    # Hidden fully connected layer with 256 neurons\n",
    "    layer_2 = tf.add(tf.matmul(layer_1, weights['h2']), biases['b2'])\n",
    "    layer_2 = tf.nn.sigmoid(layer_2)\n",
    "    #layer_2 = tf.nn.dropout(layer_2, 0.9)\n",
    "    # Output fully connected layer with a neuron for each class\n",
    "    layer_3 = tf.add(tf.matmul(layer_2, weights['h3']), biases['b3'])\n",
    "    layer_3 = tf.nn.sigmoid(layer_3) \n",
    "    \n",
    "    out_layer = tf.matmul(layer_3, weights['out']) + biases['out']\n",
    "    return out_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct model\n",
    "logits = neural_net(X)\n",
    "\n",
    "\n",
    "class_weights = tf.constant([[1.0, 20.0]])\n",
    "# Define loss and optimizer\n",
    "#loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "#    logits=logits, labels=Y))\n",
    "loss_op = tf.reduce_mean(tf.nn.weighted_cross_entropy_with_logits(\n",
    "    logits=logits, targets=Y,pos_weight=class_weights))\n",
    "\n",
    "\n",
    "# your class weights\n",
    "#class_weights = tf.constant([[1.0, 3.0]])\n",
    "# deduce weights for batch samples based on their true label\n",
    "#weights_imb = tf.reduce_sum(class_weights * Y, axis=1)\n",
    "# compute your (unweighted) softmax cross entropy loss\n",
    "#unweighted_losses = tf.nn.softmax_cross_entropy_with_logits(logits= logits,labels=Y)\n",
    "# apply the weights, relying on broadcasting of the multiplication\n",
    "#weighted_losses = unweighted_losses * weights_imb\n",
    "# reduce the result to get your final loss\n",
    "#loss_op = tf.reduce_mean(weighted_losses)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "train_op = optimizer.minimize(loss_op)\n",
    "\n",
    "# Evaluate model (with test logits, for dropout to be disabled)\n",
    "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "pred_tf=tf.argmax(logits, 1)\n",
    "\n",
    "# Initialize the variables (i.e. assign their default value)\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# Start training\n",
    "\n",
    "no_iterations = int(end/batch_size)-2\n",
    "print(no_iterations)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    # Run the initializer\n",
    "    sess.run(init)\n",
    "\n",
    "    for step in range(1, 30):\n",
    "        for no_batch in range(0,no_iterations):\n",
    "            \n",
    "            batch_x = X_train_std[(no_batch*batch_size) :((no_batch+1)*batch_size) ]\n",
    "            batch_y = Y_bin_train[(no_batch*batch_size) :((no_batch+1)*batch_size) ]\n",
    "            # Run optimization op (backprop)\n",
    "            sess.run(train_op, feed_dict={X: batch_x, Y: batch_y})\n",
    "            #if step % display_step == 0 or step == 1:\n",
    "                # Calculate batch loss and accuracy\n",
    "        loss, acc = sess.run([loss_op, accuracy], feed_dict={X: X_train_std,Y: Y_bin_train})\n",
    "        print(\"Step \" + str(step) + \", Minibatch Loss= \" + \\\n",
    "                      \"{:.4f}\".format(loss) + \", Training Accuracy= \" + \\\n",
    "                      \"{:.3f}\".format(acc))\n",
    "        print(\"Testing Accuracy:\", \\\n",
    "        sess.run(accuracy, feed_dict={X: X_test_std,\n",
    "                                      Y: Y_bin_test}))\n",
    "    print(\"Optimization Finished!\")\n",
    "\n",
    "    # Calculate accuracy for MNIST test images\n",
    "    print(\"Testing Accuracy:\", \\\n",
    "        sess.run(accuracy, feed_dict={X: X_test_std,\n",
    "                                      Y: Y_bin_test}))\n",
    "    test_pred= sess.run(pred_tf, feed_dict={X: X_test_std,Y: Y_bin_test})\n",
    "    tr_pred= sess.run(pred_tf, feed_dict={X: X_train_std,Y: Y_bin_test})\n",
    "    sub_pred= sess.run(pred_tf, feed_dict={X: X_sub_std})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74\n",
      "Step 1, Minibatch Loss= 0.9698, Training Accuracy= 0.930\n",
      "Testing Accuracy: 0.92336327\n",
      "Step 2, Minibatch Loss= 0.9128, Training Accuracy= 0.930\n",
      "Testing Accuracy: 0.92336327\n",
      "Step 3, Minibatch Loss= 0.9138, Training Accuracy= 0.930\n",
      "Testing Accuracy: 0.92336327\n",
      "Step 4, Minibatch Loss= 0.9143, Training Accuracy= 0.930\n",
      "Testing Accuracy: 0.92336327\n",
      "Step 5, Minibatch Loss= 0.9150, Training Accuracy= 0.930\n",
      "Testing Accuracy: 0.92336327\n",
      "Step 6, Minibatch Loss= 0.9153, Training Accuracy= 0.930\n",
      "Testing Accuracy: 0.92336327\n",
      "Step 7, Minibatch Loss= 0.9154, Training Accuracy= 0.930\n",
      "Testing Accuracy: 0.92336327\n",
      "Step 8, Minibatch Loss= 0.9152, Training Accuracy= 0.930\n",
      "Testing Accuracy: 0.92336327\n",
      "Step 9, Minibatch Loss= 0.9149, Training Accuracy= 0.930\n",
      "Testing Accuracy: 0.92336327\n",
      "Step 10, Minibatch Loss= 0.9145, Training Accuracy= 0.930\n",
      "Testing Accuracy: 0.92336327\n",
      "Step 11, Minibatch Loss= 0.9142, Training Accuracy= 0.930\n",
      "Testing Accuracy: 0.92336327\n",
      "Step 12, Minibatch Loss= 0.9139, Training Accuracy= 0.930\n",
      "Testing Accuracy: 0.92336327\n",
      "Step 13, Minibatch Loss= 0.9138, Training Accuracy= 0.930\n",
      "Testing Accuracy: 0.92336327\n",
      "Step 14, Minibatch Loss= 0.9137, Training Accuracy= 0.930\n",
      "Testing Accuracy: 0.92336327\n",
      "Step 15, Minibatch Loss= 0.9135, Training Accuracy= 0.930\n",
      "Testing Accuracy: 0.92336327\n",
      "Step 16, Minibatch Loss= 0.9132, Training Accuracy= 0.930\n",
      "Testing Accuracy: 0.92336327\n",
      "Step 17, Minibatch Loss= 0.9131, Training Accuracy= 0.930\n",
      "Testing Accuracy: 0.92336327\n",
      "Step 18, Minibatch Loss= 0.9131, Training Accuracy= 0.930\n",
      "Testing Accuracy: 0.92336327\n",
      "Step 19, Minibatch Loss= 0.9130, Training Accuracy= 0.930\n",
      "Testing Accuracy: 0.9231443\n",
      "Step 20, Minibatch Loss= 0.9207, Training Accuracy= 0.930\n",
      "Testing Accuracy: 0.9231443\n",
      "Step 21, Minibatch Loss= 0.9134, Training Accuracy= 0.930\n",
      "Testing Accuracy: 0.92336327\n",
      "Step 22, Minibatch Loss= 0.9126, Training Accuracy= 0.930\n",
      "Testing Accuracy: 0.92336327\n",
      "Step 23, Minibatch Loss= 0.9127, Training Accuracy= 0.930\n",
      "Testing Accuracy: 0.92336327\n",
      "Step 24, Minibatch Loss= 0.9127, Training Accuracy= 0.930\n",
      "Testing Accuracy: 0.9231443\n",
      "Step 25, Minibatch Loss= 0.9126, Training Accuracy= 0.930\n",
      "Testing Accuracy: 0.9231443\n",
      "Step 26, Minibatch Loss= 0.9126, Training Accuracy= 0.930\n",
      "Testing Accuracy: 0.92336327\n",
      "Step 27, Minibatch Loss= 0.9126, Training Accuracy= 0.930\n",
      "Testing Accuracy: 0.92336327\n",
      "Step 28, Minibatch Loss= 0.9126, Training Accuracy= 0.930\n",
      "Testing Accuracy: 0.92336327\n",
      "Step 29, Minibatch Loss= 0.9126, Training Accuracy= 0.930\n",
      "Testing Accuracy: 0.92336327\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.92336327\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot feed value of shape (23490, 27) for Tensor 'Placeholder_40:0', which has shape '(?, 18)'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-252-66760580c199>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[0mtest_pred\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred_tf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mX_test_std\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mY_bin_test\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[0mtr_pred\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred_tf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mX_train_std\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mY_bin_test\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m     \u001b[0msub_pred\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred_tf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mX_sub_std\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    898\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 900\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    901\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1109\u001b[0m                              \u001b[1;34m'which has shape %r'\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1110\u001b[0m                              (np_val.shape, subfeed_t.name,\n\u001b[1;32m-> 1111\u001b[1;33m                               str(subfeed_t.get_shape())))\n\u001b[0m\u001b[0;32m   1112\u001b[0m           \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_feedable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1113\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Tensor %s may not be fed.'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0msubfeed_t\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot feed value of shape (23490, 27) for Tensor 'Placeholder_40:0', which has shape '(?, 18)'"
     ]
    }
   ],
   "source": [
    "# Start training\n",
    "\n",
    "no_iterations = int(end/batch_size)-2\n",
    "print(no_iterations)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    # Run the initializer\n",
    "    sess.run(init)\n",
    "\n",
    "    for step in range(1, 30):\n",
    "        for no_batch in range(0,no_iterations):\n",
    "            \n",
    "            batch_x = X_train_std[(no_batch*batch_size) :((no_batch+1)*batch_size) ]\n",
    "            batch_y = Y_bin_train[(no_batch*batch_size) :((no_batch+1)*batch_size) ]\n",
    "            # Run optimization op (backprop)\n",
    "            sess.run(train_op, feed_dict={X: batch_x, Y: batch_y})\n",
    "            #if step % display_step == 0 or step == 1:\n",
    "                # Calculate batch loss and accuracy\n",
    "        loss, acc = sess.run([loss_op, accuracy], feed_dict={X: X_train_std,Y: Y_bin_train})\n",
    "        print(\"Step \" + str(step) + \", Minibatch Loss= \" + \\\n",
    "                      \"{:.4f}\".format(loss) + \", Training Accuracy= \" + \\\n",
    "                      \"{:.3f}\".format(acc))\n",
    "        print(\"Testing Accuracy:\", \\\n",
    "        sess.run(accuracy, feed_dict={X: X_test_std,\n",
    "                                      Y: Y_bin_test}))\n",
    "    print(\"Optimization Finished!\")\n",
    "\n",
    "    # Calculate accuracy for MNIST test images\n",
    "    print(\"Testing Accuracy:\", \\\n",
    "        sess.run(accuracy, feed_dict={X: X_test_std,\n",
    "                                      Y: Y_bin_test}))\n",
    "    test_pred= sess.run(pred_tf, feed_dict={X: X_test_std,Y: Y_bin_test})\n",
    "    tr_pred= sess.run(pred_tf, feed_dict={X: X_train_std,Y: Y_bin_test})\n",
    "    sub_pred= sess.run(pred_tf, feed_dict={X: X_sub_std})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9295900904571754\n",
      "precision: [0.92987606 0.42857143]\n",
      "recall: [0.99964937 0.00347625]\n",
      "fscore: [0.96350118 0.00689655]\n"
     ]
    }
   ],
   "source": [
    "precision, recall, fscore, support = score(ytrain, tr_pred)\n",
    "accuracy = accuracy_score(ytrain,tr_pred)\n",
    "print('Accuracy: {}'.format(accuracy))\n",
    "\n",
    "print('precision: {}'.format(precision))\n",
    "print('recall: {}'.format(recall))\n",
    "print('fscore: {}'.format(fscore))\n",
    "#print('support: {}'.format(support))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'all_metrics' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-52ec04631654>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf_met\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_metrics\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'C_name'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Accuracy'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Notpromoted_rec'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Promoted_rec'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'notpromoted_prec'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'promoted_prec'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'fscore_nonprom'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'fscore_prom'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'all_metrics' is not defined"
     ]
    }
   ],
   "source": [
    "#df_met=pd.DataFrame(all_metrics,columns=['C_name','Accuracy','Notpromoted_rec','Promoted_rec','notpromoted_prec','promoted_prec','fscore_nonprom','fscore_prom'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t=df_met.sort_values('Promoted_rec',ascending=True)\n",
    "t[['C_name','Accuracy','Promoted_rec','promoted_prec','fscore_prom','notpromoted_prec','Notpromoted_rec','fscore_nonprom']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_met.to_csv('../col_wise_res/col_wise_1_4high_v1.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision, recall, fscore, support = score(ytrain, tr_pred)\n",
    "accuracy = accuracy_score(ytrain,tr_pred)\n",
    "print('Accuracy: {}'.format(accuracy))\n",
    "\n",
    "print('precision: {}'.format(precision))\n",
    "print('recall: {}'.format(recall))\n",
    "print('fscore: {}'.format(fscore))\n",
    "#print('support: {}'.format(support))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision, recall, fscore, support = score(yvalid, test_pred)\n",
    "accuracy = accuracy_score(yvalid,test_pred)\n",
    "print('Accuracy: {}'.format(accuracy))\n",
    "\n",
    "print('precision: {}'.format(precision))\n",
    "print('recall: {}'.format(recall))\n",
    "print('fscore: {}'.format(fscore))\n",
    "#print('support: {}'.format(support))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_data= {'employee_id':xtestproc['employee_id'],'is_promoted':sub_pred}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.DataFrame(sub_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.to_csv(\"../results/pred3normal_nn.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "xtrain.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rf = RandomForestClassifier(n_estimators = 20, random_state = 0,max_depth=None,min_samples_split=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rf = DecisionTreeClassifier(criterion = \"gini\", max_depth=None,min_samples_split=4,random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = svm.SVC(kernel='linear', C=500, gamma=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.fit(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_pred = rf.predict(xtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_pred = rf.predict(xvalid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision, recall, fscore, support = score(ytrain, tr_pred)\n",
    "accuracy = accuracy_score(ytrain,tr_pred)\n",
    "print('Accuracy: {}'.format(accuracy))\n",
    "\n",
    "print('precision: {}'.format(precision))\n",
    "print('recall: {}'.format(recall))\n",
    "print('fscore: {}'.format(fscore))\n",
    "#print('support: {}'.format(support))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision, recall, fscore, support = score(yvalid, valid_pred)\n",
    "accuracy = accuracy_score(yvalid,valid_pred)\n",
    "print('Accuracy: {}'.format(accuracy))\n",
    "\n",
    "print('precision: {}'.format(precision))\n",
    "print('recall: {}'.format(recall))\n",
    "print('fscore: {}'.format(fscore))\n",
    "#print('support: {}'.format(support))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_data['is_promoted'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_data['department'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "l1=ts_data['employee_id'].values\n",
    "l2=tr_data['employee_id'].values\n",
    "common=np.intersect1d(l1,l2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sort(l1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sort(l2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
